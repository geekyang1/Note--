# 项目描述

## 一、校园交易平台

![image-20240205215315407](C:\Users\geekyang\AppData\Roaming\Typora\typora-user-images\image-20240205215315407.png)

### 1.为提高首页吞吐量 ，使用Wrk进行压测并优化 ，使得吞吐量显著提升 ，响应时间降低30%.

  1.将静态资源部署到nginx服务器上

（Tomcat就像大厨，专门处理运算。Nginx像是服务员，处理静态资源，碰到动态数据文去Tomcat中寻找）

  2.将页面所需的热点数据部署到Redis中去，不用去mysql中查找数据，直接在内存中取数据，速度加快。

### -------------------------------

### 2.使用Spring Cloud Gateway结合Sentinel实现负载均衡 ，限流熔断和路由转发 ，并解决跨域问题.

跨域问题：

什么是跨域，跨域是指不遵守同源策略（同源策略是一种约定，浏览器的一种安全保护机制，避免XSS,CSRF的攻击。同源要求 协议  域名 端口号三者一致。）

跨域问题的解决CORS方案

CORS（跨域资源共享）来允许跨源访问。

CORS是一种基于HTTP协议的标头机制，他可以让服务器指定浏览器可以从其他域中获取资源。

@Configuration
public class MyCorsConfiguration {

```java
@Bean
public CorsWebFilter corsWebFilter(){
    UrlBasedCorsConfigurationSource source = new UrlBasedCorsConfigurationSource();

    CorsConfiguration corsConfiguration = new CorsConfiguration();
    //1、配置跨域
    corsConfiguration.addAllowedHeader("*");
    corsConfiguration.addAllowedMethod("*");
    corsConfiguration.addAllowedOrigin("*");
    corsConfiguration.setAllowCredentials(true);

    source.registerCorsConfiguration("/**",corsConfiguration);
    return new CorsWebFilter(source);
}
```
}

### -------------------------------

### 3.为解决库存超卖问题 ，提高秒杀效率，使用Redis客户端Redisson实现分布式锁和异步编排

将查询库存信息和判断一人一单，将创建订单两项内容放到**两个服务**中去。

查询库存信息和判断一人一单使用Redis判断，将查操作交给Redis去处理，一人一单通过Redis中Set结构进行判断。如果库存充足且该用户没有购买过时，扣减库存，发送订单信息给创建订单服务。

![image-20240213192237594](C:\Users\geekyang\AppData\Roaming\Typora\typora-user-images\image-20240213192237594.png)

```java
@Override
public Result seckillVoucher(Long voucherId) {
    //获取用户
    Long userId = UserHolder.getUser().getId();
    long orderId = redisIdWorker.nextId("order");
    // 1.执行lua脚本
    Long result = stringRedisTemplate.execute(
            SECKILL_SCRIPT,//lua脚本
            Collections.emptyList(),//lua 脚本中的key参数
            voucherId.toString(), userId.toString(), String.valueOf(orderId)// lua 脚本中的value参数
    );
    int r = result.intValue();
    // 2.判断结果是否为0
    if (r != 0) {
        // 2.1.不为0 ，代表没有购买资格
        return Result.fail(r == 1 ? "库存不足" : "不能重复下单");
    }
    //TODO 保存阻塞队列
    // 3.返回订单id
    return Result.ok(orderId);
}
```

查询库存信息和判断一人一单完成后给创建订单服务发送用户id，优惠卷id，订单id。

创建订单过程中为避免库存超卖问题（单体架构中每一个JVM都有锁的id，通过锁id是否重复，来执行业务。但是分布式项目，往往一个需要布置集群，就会出现多JVM，每一个JVM只有一个锁监视器，集群就会出现多个锁监视器，就锁不住线程），所以引入Redission这种分布式锁来实现互斥性。

```java
  RLock lock = redissonClient.getLock("lock:order:" + userId);
        //获取锁对象
        boolean isLock = lock.tryLock();
       
		//加锁失败
        if (!isLock) {
            return Result.fail("不允许重复下单");
        }
        try {
            //获取代理对象(事务)
            IVoucherOrderService proxy = (IVoucherOrderService) AopContext.currentProxy();
            return proxy.createVoucherOrder(voucherId);
        } finally {
            //释放锁
            lock.unlock();
        }
```



### -------------------------------

### 4.使用RabbitMQ进行异步解耦，通过为RabbitMQ的延迟队列，解决订单超时进行自动关单.

TTL（Time to Live）：存活时间

RabbitMq延迟队列：

在最开始的时候，通过死信交换机来进行延迟发送消息（消息过期、队列消息堆积满了，最早的消息会成为死信）

下面是通过死信来实现延迟队列的步骤

![image-20240214160106181](C:\Users\geekyang\AppData\Roaming\Typora\typora-user-images\image-20240214160106181.png)

在一个消息队列中等消息（需要设置消息的TTL）死亡，然后这些死亡的消息发送到另一个交换机中（这个交换机就成为死信交换机），然后就可以实现延迟消息了

高版本的RabbitMQ提供了插件来实现这一功能

![image-20240214160501333](C:\Users\geekyang\AppData\Roaming\Typora\typora-user-images\image-20240214160501333.png)

这需要在交换机中 exchange中配置一个delayed="true"这个属性就开启了延迟消息的功能

```java
message.setDelay("10000")//以毫秒为单位，设置消息延迟发送的时间
```

**在实际情况中：**

​		消息不可能延迟发送30min，这样会导致信息堆积到MQ中，提高MQ压力。

​		实际上都会把30min拆解成10s 10s 10s 20s 20s 20s 90s 2min 5min这样的时间 将其设置成一个数组 遍历数组 给MQ发消息。

![image-20240214161812873](C:\Users\geekyang\AppData\Roaming\Typora\typora-user-images\image-20240214161812873.png)

DelayMessageProcessor是一个消息处理器（里面的核心就是		**message.setDelay("dealy")**）



### -------------------------

### 5.Feed方案选型，通过Timeline中的推模式，实现好友商品关注 , 同时实现滚动分页.

什么是Feed流 就是从传统的**用户搜索内容** 转变为  **内容匹配用户**。

![image-20240214163350275](C:\Users\geekyang\AppData\Roaming\Typora\typora-user-images\image-20240214163350275.png)

Feed流中有两种方案：

- TimeLine：不做内容筛选，只按照内容发布时间进行排序，常用于好友或者关注。例如：朋友圈
  - 优点：信息全面，不缺失。实现简单。
  - 缺点：信息噪音多，用户可能不喜欢。

- 智能排序：通过算法进行智能排序，将用户喜欢的内容推送给用户。
  - 优点：投喂用户喜欢的，粘性高，用户容易沉迷。
  - 缺点：算法不精准的话，可能会起到适得其反的效果

TimeLine的三种方案：

- 拉模式（读扩散）：存在发信箱，写信箱。当用户想看关注消息时，临时拉取关注内容。
- 推模式（写扩散）：没有发信箱。直接将用户关注的店铺信息发送到自己的收信箱的，无需临时拉取。
- 推拉集合模式	：因为有大V 存在 粉丝可能有活跃粉丝 不活跃粉丝 综合特性对于活跃粉丝使用推模式（可以随时看到自家哥哥的信息），对于不活跃粉丝使用拉模式（可能很长时间都不会登录，等到需要看的时候再拉取）



我们这个项目实现的是好友商品的关注，根据这个需求确定是推模式。



Feed流中的数据会不断更新，所以通过传统的脚表分页是不可取的（传统的脚表分页问题就是如果在查询下一页的时候插入了一条数据，那么脚表就会发生变化，有可能查询到重复数据等一系列问题。）

所以我们采用**滚动分页**

滚动分页，通过Redis 中SortedSet结构实现

需要四个参数

max：分数的最大值  如果第一次查询不需要给值，后端判断直接给0。 第n次查询就是上次查询最小值。

min：0 分数最小值。 基本固定是0

offset：偏移量。0或者 与最小值结果一样的值的个数

count：pageSize。固定值

**前端需要传递值**：

max offset

记录上一次查询数据的最小时间戳（分数的最小值），和偏移量（就是上次查询最小时间戳相等的个数）

**返回值**

内容集      最小时间戳   偏移量



```java
@Override
public Result queryBlogOfFollow(Long max, Integer offset) {
    // 1.获取当前用户
    Long userId = UserHolder.getUser().getId();
    // 2.查询收件箱 ZREVRANGEBYSCORE key Max Min LIMIT offset count
    String key = FEED_KEY + userId;
    Set<ZSetOperations.TypedTuple<String>> typedTuples = stringRedisTemplate.opsForZSet()
        .reverseRangeByScoreWithScores(key, 0, max, offset, 2);
    // 3.非空判断
    if (typedTuples == null || typedTuples.isEmpty()) {
        return Result.ok();
    }
    // 4.解析数据：blogId、minTime（时间戳）、offset
    List<Long> ids = new ArrayList<>(typedTuples.size());
    long minTime = 0; // 2
    int os = 1; // 2
    for (ZSetOperations.TypedTuple<String> tuple : typedTuples) { // 5 4 4 2 2
        // 4.1.获取id
        ids.add(Long.valueOf(tuple.getValue()));
        // 4.2.获取分数(时间戳）
        long time = tuple.getScore().longValue();
        if(time == minTime){
            os++;
        }else{
            minTime = time;
            os = 1;
        }
    }
	os = minTime == max ? os : os + offset;
    // 5.根据id查询blog
    String idStr = StrUtil.join(",", ids);
    List<Blog> blogs = query().in("id", ids).last("ORDER BY FIELD(id," + idStr + ")").list();

    for (Blog blog : blogs) {
        // 5.1.查询blog有关的用户
        queryBlogUser(blog);
        // 5.2.查询blog是否被点赞
        isBlogLiked(blog);
    }

    // 6.封装并返回
    ScrollResult r = new ScrollResult();
    r.setList(blogs);
    r.setOffset(os);
    r.setMinTime(minTime);

    return Result.ok(r);
}
```



### ---------------------------------

### 6.优化服务端统计内存占用大问题，使用Redis实现的HyperLogLog算法 ，进行UV统计.

HyperLogLog博客：

https://juejin.cn/post/6844903785744056333#heading-0

**UV统计-HyperLogLog**：

首先我们搞懂两个概念：

* **UV**：全称Unique Visitor，也叫独立访客量，是指通过互联网访问、浏览这个网页的自然人。1天内同一个用户多次访问该网站，只记录1次。（可以根据电脑ip来进行数据收集，也可以通过cookie进行收集）
* **PV**：全称Page View，也叫页面访问量或点击量，用户每访问网站的一个页面，记录1次PV，用户多次打开页面，则记录多次PV。往往用来衡量网站的流量。

通常来说UV会比PV大很多，所以衡量同一个网站的访问量，我们需要综合考虑很多因素，所以我们只是单纯的把这两个值作为一个参考值



***前后端的责任：*** 

**前端**负责**数据的<u>收集</u>**。后端负责数据的<u>**存储**</u>和**<u>处理统计</u>**。

作为后端程序员我们需要面对的问题就是储存和处理数据，那么该用什么方式进行数据的储存和处理那？

Redis 和 Mysql 这两者都可以进行数据的储存，但是一般数据的存储要面临的都是海量的数据，压力比较大。所以我选择使用Redis中实现的HyperLogLog算法 来对数据进行压缩，保证数据能在**16kb**以下，可以大大减小内存压力，**有小于0.81％的误差**但是在UV统计中可以忽视。

HyperLogLog算法

为什么要使用hyperloglog算法，如果使用常规的HashMap存储数据也可以将数据存储下来，但是他所占用的内存是
$$
数据量*（key+value）
$$
如果有海量的数据量内存占比将会大大提高，而1Long的数据使用HyperLogLog来统计只需要12k。

**LogLog的估算公式**

![image-20240216121909205](C:\Users\geekyang\AppData\Roaming\Typora\typora-user-images\image-20240216121909205.png)

![image-20240216122039710](C:\Users\geekyang\AppData\Roaming\Typora\typora-user-images\image-20240216122039710.png)

因为要实现调和平均数，就需要有多项数相加，那么就牵扯到**分桶**的问题上来了。

分桶就是分多少轮。抽象到计算机上就是，存储的是一个以单位是比特(bit)，长度为L的数组S，将S平均分为m组，注意这个 m 组，就是对应多少轮，然后每组所占有的比特个数是平均的，设为 P
$$
L = m*p=S.length
$$
以k为单位
$$
S=L/8/1024
$$
在 `Redis` 中，`HyperLogLog`设置为：m=16834，p=6，L=16834 * 6。占用内存为=16834 * 6 / 8 / 1024 = 12K

**HyperLogLog的估算公式**

![image-20240216123909566](C:\Users\geekyang\AppData\Roaming\Typora\typora-user-images\image-20240216123909566.png)

**Redis中对HyperLogLog的应用**

首先，在redis中HyperLogLog是一种高级的数据结构。他包括但不限于一下两条命令：

- pfadd key value ，将key对应的一个value存进去
- pfcount key 统计一个key对应多少个value

对应到UV统计上，key不就是页面名称，value就是访问页面的独立用户id。

## 二、信安竞赛平台

### 1.使用JWT生成Token，用Redis存储验证码和TokenID，使用拦截器对传来的Token进行认证和鉴权.

使用JWT生成token的目的是 服务器压力小 同时可以携带一些用户信息

### ---------------------------------



### 2.使用Spring AOP对其他模块的关键功能进行埋点，使用DFA算法进行敏感词过滤.

对关键功能进行日志管理，使用Logback框架，配合springAOP对用户信息，请求路径，ip，参数 响应结果，状态，响应状态描述，时间进行记录。

并且将该信息记录到文件中去。

**在本项目中**，主要就是对于考试信息的记录，使用@After注解，记录考试人员信息，成绩。将该信息封装为json，持久化到硬盘当中

### ---------------------------------

### 3.巧用MyBatis中的#{}和${}，设计出供多个模块共用的分数分段算法.

  	解决重复代码的过程，类似封装工具

mybatis中case when 语句的使用

```sql
SELECT
	CASE
		WHEN SCORE>=90 THEN '优秀'，
		WHEN SCORE<90 AND SCORE>=80 THEN '良好',
		WHEN SCORE<80 AND SCORE>=70 THEN '中等',
		WHEN SCORE<70 AND SCORE>=60 THEN '及格',
		ELSE '不及格'
	END AS grade
	COUNT(*) AS count	
FROM test
WHERE username='pwd'
GROUP BY grade
    
```

同时这种分段分数可以使用在其他模块上，就需要将表名，字段名能自定义输入。

但是Mybatis中的#{}输入的内容都是带' ' 在FROM 与 WHERE 字段后面使用都是不合法的（前者使用后，语法错误。后者使用后 变成常量值） 这时候就需要${} 来实现 ${} 输入的内容不带'' 同时可以作为sql语句的关键字

```sql
SELECT
	CASE
		WHEN SCORE>=90 THEN '优秀'，
		WHEN SCORE<90 AND SCORE>=80 THEN '良好',
		WHEN SCORE<80 AND SCORE>=70 THEN '中等',
		WHEN SCORE<70 AND SCORE>=60 THEN '及格',
		ELSE '不及格'
	END AS grade
	COUNT(*) AS count
FROM ${tbName}
WHERE ${tbIdName} = #{idValue}
GROUP BY grade
```

设置一套统一的评分方式，就可以共用同一套评分。

### ---------------------------------

### 4.l 使用Docker的Dockerﬁle对项目进行部署并挂载数据卷.

单体项目部署，需要jdk的依赖（原因是除了jdk的依赖，其他依赖均已在项目jar包中），导入jdk依赖可以使用

但是mysql 这种数据库 redis rabbitmq 这种非依赖的中间件需要自己手动创建容器

java：8-alpine

```dockerfile
FROM java:8-alpine
COPY ./app.jar /tmp/app.jar 这行指令将当前目录下的 app.jar 文件复制到容器内的 /tmp/app.jar 路径。
EXPOSE 8090这行指令声明了容器内部的应用程序将使用的端口号为 8090。这只是声明了容器内部的端口映射，并不会自动将容器的端口映射到主机上。
ENTRYPOINT java -jar /tmp/app.jar 这行指令指定了容器启动时要运行的命令。在这种情况下，它运行了一个 Java 命令，使用 -jar 参数来执行 /tmp/app.jar 文件。
```

![image-20240204211745233](C:\Users\geekyang\AppData\Roaming\Typora\typora-user-images\image-20240204211745233.png)

![image-20240204215003218](C:\Users\geekyang\AppData\Roaming\Typora\typora-user-images\image-20240204215003218.png)

这些是创建镜像的内容

镜像创建完毕 需要 docker run 命令 构建容器 在其中-v 参数来进行resource目录内容的挂载。

**挂载数据卷**

![image-20240204214444208](C:\Users\geekyang\AppData\Roaming\Typora\typora-user-images\image-20240204214444208.png)

![image-20240204214533527](C:\Users\geekyang\AppData\Roaming\Typora\typora-user-images\image-20240204214533527.png)

在配置文件中设置 ， 该 配置文件在虚拟机上的名字与位置 

然后在docker run  -v 中挂载数据卷

![image-20240204220040388](C:\Users\geekyang\AppData\Roaming\Typora\typora-user-images\image-20240204220040388.png)

![image-20240204220251136](C:\Users\geekyang\AppData\Roaming\Typora\typora-user-images\image-20240204220251136.png)